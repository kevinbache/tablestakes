cluster_name: aws-m4-g4dn-d500-5

provider:
    type: aws
    region: us-west-2
    availability_zone: us-west-2a,us-west-2b
auth:
    ssh_user: ubuntu

min_workers: 0
initial_workers: 4
max_workers: 4

autoscaling_mode: default
target_utilization_fraction: 0.8
idle_timeout_minutes: 20

# m4.large $0.0342 per Hour
# 2020.07.22: 'latest_dlami'. Using 'ami-09f2f73141c83d4fe', which is the default AWS Deep Learning AMI (Ubuntu 18.04) V26.0 for your region (us-west-1).
# todo: create AMI containing all needed packages for quick cluster startup
head_node:
    InstanceType: m4.large
    ImageId: latest_dlami
    BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
              VolumeSize: 500

worker_nodes:
    InstanceType: g4dn.xlarge
    ImageId: latest_dlami
    InstanceMarketOptions:
        MarketType: spot
        SpotOptions:
            MaxPrice: "0.30"
#    BlockDeviceMappings:
#        - DeviceName: /dev/sda1
#          Ebs:
#              VolumeSize: 1000

# Remote -> Local
file_mounts: {
    "/tmp/chillpill_current_branch_sha": "~/projects/chillpill/.git/refs/heads/master",
    "/tmp/tablestakes_current_branch_sha": "~/projects/tablestakes/.git/refs/heads/master",
    ~/.logger_api_key: ~/.logger_api_key,
    "~/lib/": "~/projects/tablestakes/python/lib/",
}

setup_commands:
    # prep up
    - grep -qxFi 'source activate pytorch_p36' ~/.bashrc || echo 'source activate pytorch_p36' >> ~/.bashrc

    # deel learning stuff
    - source activate pytorch_p36 && pip install \
        torchvision tabulate tensorboard tensorboardX \
        pytorch-lightning hyperopt neptune-client \
        jupyter ipywidgets bokeh "boto3>=1.10.44"

    # ray
    - source activate pytorch_p36 && pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-1.1.0.dev0-cp37-cp37m-manylinux1_x86_64.whl
    - source activate pytorch_p36 && pip install ray[all]
    # for https://docs.ray.io/en/stable/webui.html
    - source activate pytorch_p36 && jupyter nbextension enable --py --sys-prefix widgetsnbextension

    # my stuff
    - mkdir -p ~/projects

    - source activate pytorch_p36 && pip install lib/pytorch_fast_transformers-0.3.0-cp37-cp37m-linux_x86_64.whl
    - source activate pytorch_p36 && pip install --upgrade "cloudpickle>=1.6.0"

    - test -e projects/chillpill || git clone https://github.com/kevinbache/chillpill.git ~/projects/chillpill
    - cd projects/chillpill && git fetch && git checkout `cat /tmp/chillpill_current_branch_sha`
    - source activate pytorch_p36 && pip install --editable ~/projects/chillpill/

    - test -e projects/tablestakes/python || git clone https://github.com/kevinbache/tablestakes.git ~/projects/tablestakes
    - cd projects/tablestakes && git fetch && git checkout `cat /tmp/tablestakes_current_branch_sha`
    # todo: recompile fast-transformers on gpu node to get gpu speed?
    - source activate pytorch_p36 && pip install --editable ~/projects/tablestakes/python/

# note the virtual env activation
head_start_ray_commands:
    - ray stop
    - ulimit -n 65536; source activate pytorch_p36 && ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml

worker_start_ray_commands:
    - ray stop
    - ulimit -n 65536; source activate pytorch_p36 && ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076
